# GPU 

## GPU 硬件结构

GPU 是一个 SM (流式多处理器) 的阵列，每一个 SM 包含 N 个计算核， 通常来说 N=128， 一个 GPU 设备包含多个 SM。
一个 SM 包含:
1. 指令缓存: 用于缓存 GPU 指令
2. 线程束(Wrap)调度器: 进行线程束的调度，负责将软件线程分配到计算核上
3. 一定数量的共享内存;
4. 内存的读写单元(Load-Store Unit, LSU): 一般有多个，负责将值加载到内存或者从内存中加载值;
5. 特殊函数单元(Special-Function Units, SFU)： 有多个，用于处理三角函数这样的数学函数还有倒数;
6. CUDA Core: 一个 SM 内部包含多个 CUDA Core，每一个 CUDA Core 包含一个浮点单元和整数单元;
7. 一定数量的寄存器;
8. L1 缓存
9. 常量内存的缓存
9. 纹理和表面内存的缓存

## CUDA 线程结构
1. 由一个内核启动的所有线程统称为一个网格 (Grid)，同一个网格中的所有线程共享相同的全局内存空间
2. 每一个网格包含多个线程块 (Block)； 
3. 每一个线程块由多个线程 (Thread) 构成，每个线程都有自己的指令地址计数器和寄存器状态，利用自身的数据执行当前的指令。

## 关于线程束

当前 GPU 的线程束大小为 32。 GPU 会将一个线程块中的线程划分为若干个线程束，交给线程束调度器。

线程束和 CPU 中的线程类似，有就绪，运行，阻塞等多个状态。

一个 SM 有多少个线程调度器就能够同时执行多少个线程束。

线程束是 GPU 硬件调度的最小粒度，是并行处理的基本单元，线程束中的所有线程执行相同的指令，即单指令多线程（SIMT）

单指令多线程的特点：
+ 每一个线程都有自己的指令地址计数器
+ 每一个线程都有自己的寄存器状态
+ 每一个线程可以有自己的执行路径（SIMD, XMM或者YMM 寄存器中的数据要么全部执行，要么都不执行，不支持if），但是这会带来线程束的分化问题

**线程束的分化**：

存在 if...else...语句时，线程束中的线程不能同时运行 if 和 else 中的语句，需要分开来运行，这就是线程束的分化问题。
具体的说，就是该线程束会线运行满足 if 条件部分的线程，此时 else 条件的线程冻结，然后运行 else 部分的线程，if 部分的线程冻结。
这里我们可以看出 GPU 不适合逻辑复杂的控制密集型任务。

如何避免线程束的分化：调整分支粒度使得每一个分支对应的线程数为线程束大小的整数倍。

## 软硬件组织结构对比

+ 一个线程块只能分配到一个 SM 上，不存在一个线程块分配到多个 SM 上；
+ 多个线程块可以分配到同一个 SM 上；
+ 应该尽可能的把线程均分到 SM 上；
+ 一个线程块中的线程可以被分到多个线程束中去.

线程网格中的线程块数量应该要为显卡SM数量的整数倍。


## 关于线程块

为什么需要线程块？

+ 通信：shared memory 是以 Block 为单位分配的，一个 Block 内的线程共享share memory；
+ 同步： __syncthreads 是以线程块为单位同步的；
+ 可拓展性：为了使得 CUDA 程序可以在不同 SM 数量的 GPU 上运行，因此线程块可以分布在多个 SM 中


